#!/usr/bin/env python
"""
A command line tool to calculate time and space aggregation statistics
"""
import numpy as np

import argparse

from ddice.dataset.netcdf4 import netCDF4Dataset
from ddice.field import CFField
from ddice.field import grouping
from ddice.field import functions

parser = argparse.ArgumentParser(description='Time and space aggregation statistics')

parser.add_argument('source', help='source data uri and fields in the form uri:fieldname1,fieldname2,..,fieldnameN')
parser.add_argument('--target', '-t', required=True, help='target data uri')
parser.add_argument('--groupby', '-g', nargs='*', help='groupby coordinate, function, and arguments using syntax: coordinate:function,arg1,arg2,..,argN')
parser.add_argument('--apply', '-a', nargs='*', help='function(s) to apply to each group')
parser.add_argument('--post', '-p', help='post processing function to apply')

args = parser.parse_args()
print(args)

# Process source argument of the form uri:
source_parts = args.source.split(':')

if len(source_parts) > 1:
	fieldfilter = set(source_parts[1].split(','))

else:
	fieldfilter = ''


source = netCDF4Dataset(uri=source_parts[0])

print('source dimensions: {}'.format(source.dimensions))
print('source variables: {}'.format(source.variables.keys()))


fieldselect = set(source.variables.keys())

if fieldfilter:
	fieldselect = list(fieldselect & fieldfilter)
else:
	fieldselect = list(fieldselect)

print('selected fields: {}'.format(fieldselect))

field = CFField(source.variables[fieldselect[0]])


for opid in range(0, len(args.apply)):

	# Try and get the apply function
	apply_parts = args.apply[opid].split(':')

	try:
		apply_func = eval('functions.{}'.format(apply_parts[0]))
	except:
		raise Exception('Cannot find function {} in functions modules'.format(apply_parts[0]))


	apply_kwargs = {}

	if len(apply_parts) > 1:
		apply_args = apply_parts[1:]


		for arg in apply_args:
			try:
				name, value = arg.split('=')
			except:
				pass

			apply_kwargs[name] = value

	apply_kwargs_string = ''.join(['{}={}'.format(name, value) for name, value in apply_kwargs.items()])

	print("applying function {}({})".format(apply_parts[0], apply_kwargs_string))

	# Try and get grouping function

	# Either there is only one, or we find the matching one of a sequence
	if opid < len(args.groupby):
		groupby_parts = args.groupby[opid].split(':')

	else:
		groupby_parts = args.groupby[0].split(':')


	groupby_coordinate = groupby_parts[0]

	try:
		function_parts = groupby_parts[1].split(',')
	except:
		raise Exception('grouping argument must specify both coordinate and grouping function name. eg: time:yearmonth')

	try:
		groupby_function = eval('grouping.{}'.format(function_parts[0]))
		groupby_args = function_parts[1:]
	except:
		raise Exception('failed to identify grouping function: '.format(function_parts[0]))

	print('grouping function: {}({})'.format(groupby_parts[0], groupby_args))

	# Index the groups
	groups = field.groupby(groupby_coordinate, groupby_function)

	print('{} groups ({}) indexed'.format(len(groups.groups), function_parts[0]))
	print(field.coordinate_variables)

	ds, field = field.apply(groups, apply_parts[0], **apply_kwargs)


target_parts = args.target.split(':')

if len(target_parts) > 1:
	target_varname_parts = target_parts[1].split(',')

	ds.variables[target_varname_parts[0]] = field.variable

	for expr in target_varname_parts[1:]:
		key, value = expr.split('=')
		ds.variables[target_varname_parts[0]].attributes[key] = value

	del(ds.variables[field.variable.name])


# Create the target dataset
target = netCDF4Dataset(uri=target_parts[0], dataset=ds)








